---
title: "Inferentielles Denken"
output: 
  learnr::tutorial:
    progressive: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(mosaic)
checker <- function(label, user_code, check_code, envir_result, evaluate_result, ...) {
  list(message = check_code, correct = TRUE, location = "append")
}
tutorial_options(exercise.timelimit = 60, exercise.checker = checker)

Linda <- read.csv2("Linda.csv")

Linda <- Linda %>%
  na.omit()

Linda2 <- Linda %>%
  mutate(linda = case_when(linda == "Linda ist Bankangestellte und in der Frauenbewegung aktiv." ~ "Falsch",
                           linda == "Linda ist Bankangestellte." ~ "Richtig"))
set.seed(1896)
Nullvtlg <- do(10000) * rflip(n = 212, prob = 0.13)

set.seed(1896)
Bootvtlg <- do(10000) * prop(~linda, success = "Richtig", data = resample(Linda2))
```

## Willkommen

Daten umfassen in aller Regel viele Informationen. Aber sie sind in gewisser Hinsicht **zufällig**, z. B. durch eine *zufällige* Stichprobe. 

Daher: *Nur* weil wir *etwas* in unseren Daten sehen heißt das *nicht*, dass das auch allgemein so ist. Vielleicht wurden wir zu unseren Schlussfolgerungen vom Zufall verführt...

In diesem Tutorial sollen Sie die Grundgedanken der induktiven Statistik kennen lernen: Kenntnis von Variation und Zufall kann vor vermeintlicher Sicherheit schützen.


## Linda

### Vorstellung 

Dürfen wir vorstellen:

> Linda ist 31 Jahre alt, single, offen und klug. Sie hat Philosophie studiert. Als Studentin interessierte sie sich sehr für Diskriminierung und soziale Gerechtigkeit. Außerdem hat Linda an Anti-Globalisierungs-Demonstrationen teilgenommen. Hier nun zwei alternative Aussagen zu Linda. 

```{r linda, echo=FALSE}
question("Welche davon ist wahrscheinlicher?",
  answer("Linda ist Bankangestellte und in der Frauenbewegung aktiv.", message="Falsch: Es ist wahrscheinlicher nur Bankangestellte zu sein als gleichzeitig Bankangestellte und in der Frauenbewegung. Die Lindas die beides sind, sind eine Teilmenge der Lindas die Bankangestellte sind."),
  answer("Linda ist Bankangestellte.", correct = TRUE, "Richtig: Es ist wahrscheinlicher nur Bankangestellte zu sein als gleichzeitig Bankangestellte und in der Frauenbewegung. Die Lindas die beides sind, sind eine Teilmenge der Lindas die Bankangestellte sind.")
)
```

### Trugschluss

Und?! Richtig gelegen? Wenn nicht: nicht schlimm! Sie sind in guter Gesellschaft: siehe das berühmte Paper: Tversky, A., & Kahneman, D. (1983). Extensional versus intuitive reasoning: The conjunction fallacy in probability judgment. Psychological review, 90(4), 293--315. [https://psycnet.apa.org/doi/10.1037/0033-295X.90.4.293](https://psycnet.apa.org/doi/10.1037/0033-295X.90.4.293).

Die Wochenzeitung DIE ZEIT und das briq-Institut haben im Rahmen einer Studie [Was wissen die Deutschen über Wirtschaft?](https://news.briq-institute.org/de/2018/02/08/die-deutschen-wissen-zu-wenig-ueber-wirtschaft/) auch diese Frage gestellt. Richtig lagen gerade einmal $13\,\%$!


### FOM-Studierende und Linda

Im Rahmen einer freiwilligen Online-Befragung zu Beginn eines Semesters an der FOM wurden Daten, u. a. zur oben genannten Frage, erhoben.

#### Vorbereitung zur Analyse

Installiertes Paket `mosaic` laden:

```{r mosaic}
library(mosaic)
```


Die Daten einlesen, Datenformat `csv` mit Semikolon `;` als Datentrennzeichen und Komma `,` als Dezimaltrennzeichen. Variablennamen in der ersten Zeile.


```{r Einlesen, eval=FALSE}
Linda <- read.csv2("Linda.csv")
```

*Hinweis*: Wenn Sie später selber Daten einlesen, müssen Sie ggf. Pfade etc. anpassen.


#### Ergebnis FOM-Studierende

```{r lindafom, echo=FALSE}
question("Was glauben Sie?",
  answer("FOM-Studierende haben besser als die Allgemeinheit in der ZEIT-Studie abgeschnitten.", correct = TRUE, "Richtig: Insbesondere können wir mit Statistik solche Vermutungen empirisch überprüfen."),
    answer("FOM-Studierende haben in etwa wie die Allgemeinheit in der ZEIT-Studie abgeschnitten.", message="Nein, aber wir können wir mit Statistik solche Vermutungen empirisch überprüfen."),
      answer("FOM-Studierende haben schlechter als die Allgemeinheit in der ZEIT-Studie abgeschnitten.", message="Nein, aber wir können wir mit Statistik solche Vermutungen empirisch überprüfen.")
)
```

```{r tally, exercise = TRUE, eval=FALSE}
tally( ~ linda, data = Linda)
```

Die Option `format = "proportion"` ermöglicht es, im Befehl `tally()` die Anteile auszugeben. Ersetzen Sie den Platzhalter `___` entsprechend um die Anteile zu erhalten:

```{r tallyprop, exercise = TRUE, eval=FALSE}
tally( ~ linda, data = Linda, ____)
```

```{r tallyprop-solution}
tally( ~ linda, data = Linda, format = "proportion")
```

```{r lindafompop, echo=FALSE}
question("War das Ergebnis der FOM-Studiernden besser als das Ergebnis in der ZEIT-Studie?",
  answer("Ja.", correct = TRUE, "Richtig: 36% (FOM) sind mehr als 13% (DIE ZEIT)."),
    answer("Nein.", message = "Falsch: 36% (FOM) sind mehr als 13% (DIE ZEIT).")
)
```

```{r stichprobe, echo=FALSE}
question("Ist das Ergebnis zufällig?",
  answer("Ja.", correct = TRUE, "Richtig: Andere Stichproben können andere Ergebnisse ergeben."),
  answer("Nein.", message = "Falsch: Andere Stichproben können andere Ergebnisse ergeben.")
)
```

### Datenvorverarbeitung

Da die Antwortalternativen `Linda ist Bankangestellte.` und `Linda ist Bankangestellte und in der Frauenbewegung aktiv.` recht lang sind, werden diese über `mutate()` und `case_when()` in "Falsch" und "Richtig" umgewandelt:


```{r case}
Linda <- Linda %>%
  mutate(linda = case_when(linda == "Linda ist Bankangestellte und in der Frauenbewegung aktiv." ~ "Falsch",
                           linda == "Linda ist Bankangestellte." ~ "Richtig"))
```

```{r anteil}
prop( ~ linda, success = "Richtig", data = Linda)
```


## Hypothesenprüfung

Auch wenn die $13\,\%$ richtige Antworten in der ZEIT-Studie natürlich auch nur das Ergebnis einer Stichprobe sind, so gehen wir davon aus, dass das Ergebnis für die Allgemeinbevölkerung gilt, d. h., für den Anteil der richtigen Antworten $\pi$ gilt: $$\pi=0.13$$.

In der Stichprobe der FOM-Studierenden sehen wir einen Anteil von $p=`r round(prop( ~ linda, success = "Richtig", data = Linda),2)`$.

*Beweist* eine Abweichung in einer Stichprobe, dass es eine allgemeine Abweichung gibt?

**Nein!** Zufall und Variation: Vielleicht waren in unserer Stichprobe *zufällig* besonders viele, die die Frage richtig beantwortet haben -- vielleicht sogar durch raten.


### Nullmodell

Nehmen wir hypothetisch an, dass sich der Anteil der richtigen Antworten in der Umfrage unter FOM-Studierenden nicht von dem Anteil in der ZEIT-Studie (Allgemeinbevölkerung) unterscheidet.

```{r simp, echo=FALSE}
question("Welcher Anteil würde in diesem hypothetischen Modell für die FOM-Studierenden gelten?",
  answer("13%", correct = TRUE, "Richtig: Wenn es keinen Unterschied zur Allgemeinbevölkerung gibt, würde der Anteil wie dort bei 13% liegen."),
  answer("36%", message = "Falsch: Wenn es keinen Unterschied zur Allgemeinbevölkerung gibt, würde der Anteil der richtigen Antworten bei FOM-Studierenden so hoch wie in der Allgemeinbevölkerung sein."),
  answer("50%", message = "Falsch: Wenn es keinen Unterschied zur Allgemeinbevölkerung gibt, würde der Anteil der richtigen Antworten bei FOM-Studierenden so hoch wie in der Allgemeinbevölkerung sein.")
  )
```


### Simulation Nullmodell

**Wenn** es keinen Unterschied gibt, d. h. auch für FOM-Studierende gelte $\pi=0.13$, dann können wir entsprechende *Stichproben* simulieren -- und unter diesem Modell vorhersagen, in welchem Bereich die Anteile $p$ der Stichproben wahrscheinlich liegen.

In der vorliegenden Stichprobe liegen $n=`r nrow(Linda)`$ Beobachtungen vor:

```{r, nrow}
nrow(Linda)
```

Mit dem Befehl `rflip()` können wir einen (fiktiven) Münzwurf simulieren. Dabei ist die Option `n` der Stichprobenumfang und `prob` die Erfolgswahrscheinlichkeit.

```{r rflip, exercise = TRUE, eval=FALSE}
rflip(n = 212, prob = 0.13)
```

Wenn Sie öfter auf `Run Code` drücken, sehen Sie, dass auch der Anteil in den (simulierten) Stichproben variiert.

Über `set.seed()` wird der Zufall reproduzierbar, das Ergebnis der $n$ *Münzwürfe* ändert sich nicht mehr:

```{r setseed, exercise = TRUE, eval=FALSE}
set.seed(1896)

rflip(n = 212, prob = 0.13)
```


### Stichprobenverteilung

Unsicherheit durch Zufall und Variation. 

Wir können aber viele Stichproben (mit $n=212$) gemäß unseres hypothetischen Modells (mit $\pi=0.13$) simulieren, und sehen wie der Anteil der richtigen Antworten ($p$) dann variiert.

Dazu wiederholen wir den zufälligen Münzwurf (`rflip()`) mit Hilfe von `do() *`, z. B. simulieren wir $100$ verschiedene Stichproben über:

```{r do}
set.seed(1896)

Nullvtlg <- do(100) * rflip(n = 212, prob = 0.13)
```

Die Stichprobenverteilung des Anteils unter den Annahmen des Nullmodells sieht dann wie folgt aus:

```{r hist}
gf_histogram( ~ prop, data = Nullvtlg)
```

Für den Mittelwert und die Streuung (Standardfehler) der Anteile gilt:

```{r}
mean( ~ prop, data = Nullvtlg)
sd( ~ prop, data = Nullvtlg)
```

Im Mittelwert haben die Stichproben einen Anteil von $\approx 0.13$, aber auch kleinere oder größere Anteile kommen vor.

Vielleicht sind $100$ Simulationen zu wenig. Ändern Sie den Code, so dass wir $10000$ Stichproben simulieren.

```{r stipro, exercise = TRUE, eval=FALSE}
set.seed(1896)

Nullvtlg <- do(100) * rflip(n = 212, prob = 0.13)

gf_histogram( ~ prop, data = Nullvtlg)
```

```{r stipro-solution}
set.seed(1896)

Nullvtlg <- do(10000) * rflip(n = 212, prob = 0.13)

gf_histogram( ~ prop, data = Nullvtlg)
```


```{r sipro0, include=FALSE}
set.seed(1896)

Nullvtlg <- do(10000) * rflip(n = 212, prob = 0.13)

gf_histogram( ~ prop, data = Nullvtlg)
```


### p-Wert

Vergleichen wir das Modell (mit $\pi=0.13$) mit dem Ergebnis unserer Daten, d. h. mit $p=0.36$:

```{r p0, exercise = TRUE}
gf_histogram( ~ prop, data = Nullvtlg) %>%
  gf_vline(xintercept = 0.36, color = "red")
```


```{r p0q, echo=FALSE}
question("Wenn das Nullmodell stimmt: Ist dann der Anteil der Stichprobe ein übliches Ergebnis?",
  answer("Ja", message = "Falsch: Wenn das Modell stimmt sind Anteile zwischen ungefähr 8% und 18% wahrscheinlich, nicht ein Anteil von 36%."),
  answer("Nein", correct = TRUE, message = "Richtig: Wenn das Modell stimmt sind Anteile zwischen ungefähr 8% und 18% wahrscheinlich, nicht ein Anteil von 36%.")
  )
```

```{r zweifel, echo=FALSE}
question("Haben Sie datengestüzt Zweifel daran, dass das Nullmodell stimmt?",
  answer("Ja", correct = TRUE, message = "Richtig: Wenn das Nullmodell stimmt sind Anteile zwischen ungefähr 8% und 18% wahrscheinlich, nicht ein Anteil von 36%. Die Daten scheinen nicht gut zu dem angenommenen Modell zu passen."),
  answer("Nein", message = "Falsch: Wenn das Nullmodell stimmt sind Anteile zwischen ungefähr 8% und 18% wahrscheinlich, nicht ein Anteil von 36%. Die Daten scheinen nicht gut zu dem angenommenen Modell zu passen.")
  )
```

Der **p-Wert** gibt an, wie oft wir im (simulierten) Modell (der **Nullhypothese** $H_0$) in einer Stichprobe eine mindestens so große Abweichung sehen würden, wie die, die wir in den Daten gesehen haben.

```{r pval, exercise = TRUE}
prop( ~ prop >= 0.36, data = Nullvtlg)
```

Der Anteil der FOM-Studierenden, die die *Linda*-Frage richtig beantwortet haben, liegt mit $p=0.36$ daher **signifikant** über $\pi=0.13$, dem Anteil in der Allgemeinbevölkerung laut Studie von DIE ZEIT und dem briq-Institut: [Was wissen die Deutschen über Wirtschaft?](https://news.briq-institute.org/de/2018/02/08/die-deutschen-wissen-zu-wenig-ueber-wirtschaft/).


### Stichprobenumfang

In keiner der $10000$ Simulationen im Modell mit $\pi=0.13$ kam eine Stichprobe mit $n=212$ Beobachtungen vor, die mindestens einen Anteil von $p=0.36$ hatten. Mit einem p-Wert $<\frac{1}{10000}$ würde man die Nullhypothese $H_0: \pi=0.13$ verwerfen.

```{r Stipro, echo=FALSE}
question("Ist bei n=20 ein beobachteter Anteil von 0.36 wahrscheinlicher als bei n=212, wenn in Wirklichkeit der Anteil bei 0.13 liegt?",
  answer("Ja", correct = TRUE, message = "Richtig: Bei kleineren Stichproben variieren die Anteile stärker."),
  answer("Nein", message = "Falsch: Bei kleineren Stichproben variieren die Anteile stärker.")
  )
```

Ändern Sie den Code so, dass Sie einen Stichprobenumfang von $n=20$ simulieren -- anstelle von $n=212$.

```{r n20, exercise = TRUE, eval=FALSE}
set.seed(1896)

Nullvtlg <- do(1000) * rflip(n = 212, prob = 0.13)

gf_histogram( ~ prop, data = Nullvtlg) %>%
  gf_vline(xintercept = 0.36, color = "red")

prop( ~ prop>=0.36, data = Nullvtlg)
```

```{r n20-solution, eval=FALSE}
set.seed(1896)

Nullvtlg <- do(1000) * rflip(n = 20, prob = 0.13)

gf_histogram( ~ prop, data = Nullvtlg) %>%
  gf_vline(xintercept = 0.36, color = "red")

prop( ~ prop>=0.36, data = Nullvtlg)
```


## Bootstrapping

### Punktschätzung

In der **Stichprobe**  der FOM-Studierenden, die an der Umfrage teilgenommen haben, *beobachten* wir einen Anteil von $p=`r round(prop(~linda, success ="Richtig", data=Linda),2)`$. Wie groß der Anteil $\pi$ derjenigen, die richtig antworten, in der **Population** der FOM-Studierenden ist wissen wir nicht.

Was wir aber machen können: Wir können den unbekannten Wert $\pi$ *schätzen*. Dies tun wir durch den uns bekannten Anteil der Stichprobe:

```{r pidach-setup}
Linda <- Linda %>%
  mutate(linda = case_when(linda == "Linda ist Bankangestellte und in der Frauenbewegung aktiv." ~ "Falsch",
                           linda == "Linda ist Bankangestellte." ~ "Richtig"))
```

```{r pidach, exercise=TRUE}
prop(~linda, success = "Richtig", data = Linda)
```


$$\hat{\pi}=p=`r round(prop(~linda, success ="Richtig", data=Linda),2)`$$


Eine *andere*, zufällige Stichprobe aus derselben Population könnte einen *anderen* Anteil ergeben: Der Anteil ist zufällig, er variiert.

### `resample()`

Aber wie stark variiert der Anteil? $\pm 2\,\%$ oder $\pm 20\,\%$? Dies hängt u. a. vom Stichprobenumfang $n$ ab. Aber hier? Was wären bei unseren Daten andere, *kompatible* Anteilswerte?

Glücklicherweise können wir das Ziehen einer zufälligen Stichprobe simulieren. Die simulierte Stichprobe sollte aber denselben Stichprobenumfang wie die uns vorliegenden Daten haben -- und wie es sich für eine zufällige Stichprobe gehört sollte stets jede mögliche Beobachtung der *Population* die gleiche Wahrscheinlichkeit haben Teil der Stichprobe zu sein. Damit dies gelingen kann müssen wir unsere simulierte Stichprobe mit Zurücklegen aus der Originalstichprobe ziehen; die Engländerin sagt dazu *resample*.


```{r resample-setup}
Linda <- Linda %>%
  mutate(linda = case_when(linda == "Linda ist Bankangestellte und in der Frauenbewegung aktiv." ~ "Falsch",
                           linda == "Linda ist Bankangestellte." ~ "Richtig"))
```

```{r resample, exercise=TRUE, eval=FALSE}
prop(~linda, success ="Richtig", data=resample(Linda))
```

Wenn Sie öfter auf `Run Code` klicken, sehen Sie die Variation des Anteils.

Eine solche simulierte Stichprobe nennt man auch *Bootstrap-Stichprobe*.

### Bootstrap-Verteilung

Das Gute ist: Wir können das über `do() * ` ganz oft simulieren und so die Verteilung des Anteils simulieren -- Mittelwert (`mean()`) und co. gehen übrigens völlig analog.

```{r bootstrapping}
set.seed(1896)

Bootvtlg <- do(10000) * prop(~linda, success = "Richtig", data = resample(Linda))
gf_histogram( ~ prop_Richtig, data = Bootvtlg)
```


```{r kicenter, echo=FALSE}
question("Um welchen Wert variieren die Werte beim Resampling??",
  answer("Um den Wert des Modells der Nullhypothese.", message = "Falsch: Beim Resampling wurden nur die vorhandenen Daten verwendet, kein hypothetisches Modell."),
  answer("Um den Wert der Stichprobe.", correct = TRUE,  message = "Richtig: Beim Resampling wurden nur die vorhandenen Daten verwendet, kein hypothetisches Modell.")
  )
```

### Konfidenzintervall

Über den Befehl `gf_vline(xintercept = ___)` wird eine vertikale Linie an der Stelle `___` eingezeichnet. Ergänzen Sie den Code, um eine Linie an der Stelle des Punktschätzers $\hat{\pi}=p=`r round(prop(~linda, success ="Richtig", data=Linda),2)`$ einzufügen.

```{r bootsample, exercise = TRUE, eval=FALSE}
gf_histogram( ~ prop_Richtig, data = Bootvtlg) %>%
  ___
```

```{r bootsample-solution}
gf_histogram( ~ prop_Richtig, data = Bootvtlg) %>%
  gf_vline(xintercept = 0.36)
```

In welchem Bereich liegen z. B. $95\,\%$ der Anteile der Resamples? Diese Frage beantwortet z. B. das Bootstrap-Perzentil-**Konfidenzintervall**:

```{r ki, exercise = TRUE}
qdata( ~ prop_Richtig, p = c(0.025, 0.975), data = Bootvtlg)
```

Oder auch kurz mit dem Befehl `confint()`:

```{r confint, exercise = TRUE}
confint(Bootvtlg)
```

## Illustration Inferenz

Der Anteil $\pi$ im datengenerierenden Prozess, der Pouplation, ist fix, wie ein Laternenpfahl.

Der Anteil $p$ in den Daten, der Stichprobe, variiiert mit der Stichprobe, wie ein Hund der an einer elastischen Leine um den Laternenpfahl tanzt.


![](http://statistix.org/FOM/Laterne_Leine_Hund.JPG){width=80%}

Abbildung von Ella Hauke.


Je mehr Beobachtungen $n$ wir haben, stärker zieht die Leine den Hund zum Laternenpfahl, die Variation von $p$ um $\pi$ wird kleiner.

Da der Hund i.d.R. nicht genau beim Laternenpfahl steht, ist es auch immer wichtig zu wissen wir groß der Bewegungsradius, der Standardfehler $se$, ist.

Bei großen, zufälligen Stichproben hält sich der Hund, d.h. $p$, in $95\%$ der Fälle innerhalb eines Umrkreises von $\pm 2 \cdot se$  vom Laternenpfahls $\pi$ auf.

##

Dummerweise sehen wir nur einen Hund $p$ (und die Leine), nicht den Laternenpfahl $\pi$.

![](http://statistix.org/FOM/Leine-Hund.JPG){width=80%}

Abbildung von Ella Hauke.


Beim Hypothesenprüfen, gucken wir ob unser Hund ($p$) nah oder eher weit weg von der angenommenen Position der Laterne ($\pi_0$) ist. Genauer: Wir gucken wie wahrscheinlich ist es, dass der Hund mindestens so weit weg ist. Ist es (sehr) unwahrscheinlich haben wir berechtigten Zweifel an der vermuteten Position $\pi_0$.

Bei einem Konfidenzintervall grenzen wir auf Basis des Hundes den Bereich ein, in dem wir den Laternenpfahl vermuten.

Da der Hund selten (sehr) weit weg vom Pfahl ist, irrt das Verfahren selten. 
Was für unseren Hund gilt wissen wir nicht – das Vertrauen ruht auf dem Verfahren.


## Ausblick

In einem nächsten Tutorial werden Sie kennen lernen wie Sie zwei Gruppen vergleichen können.





